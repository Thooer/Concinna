基于代码库现状（特别是 `Capability.Concurrency`, `Capability.Memory`, `System.Job` 等模块），以下是针对内存管理、容器和并发模块重构的架构建议。

### 1. System.Task 细化：从“执行”到“编排”

目前的 `System.Job` (基于 `Capability.Concurrency`) 已经很好地解决了 **N:M 调度** 和 **细粒度并行** 的问题。`System.Task` 目前是一个空壳，它应该定位为 **高层任务编排系统**。

*   **任务图 (Task Graph) vs 任务树 (Job Tree)**:
    *   `Concurrency::Job` 适合处理“分治法”产生的动态、短生命周期的工作（如 `ParallelFor`）。
    *   `System.Task` 应专注于 **静态或半静态的依赖图**（Frame Graph）。例如：物理模拟必须在渲染剔除之前完成。
    *   **建议**：在 `System.Task` 中引入 `TaskGraph` 概念，支持定义长期存在的节点（Node）和边（Dependency）。在每帧开始时，将 `TaskGraph` 编译或展开为一堆 `Concurrency::Job` 并提交给调度器。

*   **数据流驱动 (Data-Driven Dependencies)**:
    *   目前的 `Job` 依赖 `Counter` 进行同步，这是控制流同步。
    *   **建议**：`System.Task` 应引入 **资源屏障 (Resource Barrier)** 概念。任务不应仅声明“我在任务 B 后运行”，而应声明“我需要写入资源 R”。系统自动计算出执行顺序，并插入适当的内存屏障（这对未来的渲染图 RenderGraph 至关重要）。

*   **主线程/渲染线程亲和性**:
    *   目前的调度器是全对等的 Worker。但游戏引擎中有些任务（如窗口消息处理、某些图形 API 调用）必须在特定线程运行。
    *   **建议**：在 `System.Task` 层引入 `PinnedTask` 概念，允许将特定任务“钉”在主线程或渲染线程，调度器需识别这种约束并由特定 Worker 窃取执行。

### 2. IO 驱动插件化：解耦 Reactor 与 Executor

目前的 `Capability.Concurrency.Driver` (基于 IOCP) 紧耦合了定时器、事件和 IO 轮询。为了支持跨平台（如 Linux io_uring）和更灵活的扩展，建议进行插件化改造。

*   **驱动接口抽象 (IDriver Split)**:
    *   目前的 `IDriver` 接口过于庞大。
    *   **建议**：将驱动拆分为三个正交的接口：
        1.  `ITimerDriver`: 仅负责时间轮管理和超时唤醒。
        2.  `IIODriver`: 负责文件/网络 IO 的提交和完成通知 (Proactor 模式)。
        3.  `ISignalDriver`: 负责内核对象（Event/Semaphore）的等待。
    *   `Scheduler` 持有这些接口的指针，而不是具体的实现。

*   **轮询策略的可配置性**:
    *   目前的 Worker 在窃取失败后进行 `Poll`。
    *   **建议**：允许配置 **专用 IO 线程** vs **混合 Worker**。
        *   *高吞吐服务器模式*：所有 Worker 都参与 Poll（当前模式）。
        *   *游戏客户端模式*：为了避免计算线程抖动，可以指定 1 个 Worker 专门负责 `Driver::Poll`，并将就绪的 Fiber 分发给其他计算 Worker。

*   **外部事件源集成**:
    *   **建议**：提供 `RegisterExternalSource(Handle)` 接口。允许将第三方库（如 SteamSocket, gRPC, 音频中间件）的事件句柄注册到引擎的 Driver 中，统一由引擎的 Reactor 驱动，避免第三方库创建私有线程。

### 3. 并发容器迁移与标准化

目前 `Capability.Concurrency` 内部有一些专用的无锁结构（`MPMCQueue`, `ChaseLevDeque`），而 `Capability.Containers` 是非线程安全的标准容器。

*   **建立 Capability.ConcurrentContainers 模块**:
    *   **建议**：将 `MPMCQueue`、`ChaseLevDeque`、`IntrusiveLockFreeStack` 从 `Concurrency` 的内部实现提升为公共模块 `Capability.ConcurrentContainers`。
    *   这使得其他系统（如 `System.Message` 或 `System.Resource`）可以复用这些高质量的无锁基建，而无需依赖调度器逻辑。

*   **统一内存模型**:
    *   目前的容器可能直接使用 `Prm::Heap` 或模板策略。
    *   **建议**：所有并发容器必须强制使用 `Capability.Memory::Allocator` 句柄。
    *   特别地，为并发容器实现 **基于 Epoch 的内存回收 (EBR)** 支持（你已经有了 `Prm.Sync:EBR`）。确保无锁容器在扩容或节点删除时，配合 `System.Job` 的 Quiescent State 进行安全回收。

*   **引入 Frame-Local Containers**:
    *   **建议**：在 `Capability.Containers` 中引入一组“帧容器”（`FrameVector`, `FrameHashMap`）。
    *   这些容器默认绑定到 `Scheduler::GetFrameAllocator()`。它们不需要复杂的扩容/释放逻辑，因为内存会在帧结束时统一 Reset。这能极大提升每帧临时数据的处理性能。

### 4. 内存管理：从机制到策略

`Capability.Memory` 已经有了很好的机制（Allocator Handle, IMemoryResource）。现在的重点是策略的应用。

*   **System.Memory 的角色转变**:
    *   目前 `System.Memory` 主要是 ThreadCache 的初始化。
    *   **建议**：将其升级为 **全局内存预算管理器**。
    *   实现 **Memory Budgeting**：为不同的子系统（Audio, Physics, Renderer）分配配额。
    *   实现 **Memory Pressure Handling**：当内存不足时，`System.Memory` 广播事件，通知各子系统（如缓存系统）释放非必要内存。

*   **调试与追踪增强**:
    *   **建议**：利用 `Meta` 模块的能力，实现一个 **Reflection-based Memory Tracker**。
    *   不仅仅记录分配了多少字节，还能通过反射信息记录“分配了什么类型的对象”。这对于分析内存碎片和泄漏极其有用。

### 5. 顶层构建与依赖管理

*   **模块化依赖图**:
    *   严格执行：`System` -> `Capability` -> `Primitive` -> `Language`。
    *   **建议**：检查 `System.Job` 是否过度依赖 `Primitive.Threading` 的具体实现。理想情况下，`System.Job` 应该只依赖 `Primitive` 的抽象接口。

*   **统一配置头 (Config.ixx)**:
    *   目前配置散落在各处。
    *   **建议**：在 `Language` 或根目录下建立统一的构建配置模块。控制：
        *   `ENABLE_FIBER_STATISTICS` (是否开启详细的调度器统计)
        *   `MEMORY_TRACKING_LEVEL` (None, Basic, FullStacktrace)
        *   `USE_OS_FIBER` vs `USE_ASM_FIBER`

### 总结：下一步的具体行动点

1.  **提取**：将 `Concurrency` 中的无锁队列提取到 `ConcurrentContainers`。
2.  **抽象**：重构 `Driver`，定义 `IIODriver` 接口，将 IOCP 实现下沉到 `Impl`。
3.  **构建**：在 `System.Task` 中实现一个简单的 DAG (有向无环图) 执行器，作为 `Job` 系统的高级封装。
4.  **集成**：让 `Vector` 和 `String` 等容器默认支持通过 `Context` 获取当前的 `FrameAllocator`，简化用户代码编写。